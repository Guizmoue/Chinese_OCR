{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0293f65e",
   "metadata": {
    "id": "0293f65e"
   },
   "source": [
    "# OCR pour Caractères Manuscrits Chinois avec OpenVINO™\n",
    "\n",
    "Dans ce tutoriel, nous réalisons la reconnaissance optique de caractères (OCR) pour des caractères manuscrits en chinois simplifié. Un guide OCR pour l’alphabet latin est également disponible dans le [notebook 208](../optical-character-recognition/optical-character-recognition.ipynb). Le modèle utilisé ici est conçu pour traiter une seule ligne de caractères à la fois.\n",
    "\n",
    "Le modèle employé dans ce notebook est [`handwritten-simplified-chinese-0001`](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/handwritten-simplified-chinese-recognition-0001/README.md). Les sorties du modèle sont décodées en texte lisible grâce aux listes de caractères [`scut_ept`](https://github.com/openvinotoolkit/open_model_zoo/blob/master/data/dataset_classes/scut_ept.txt). Ces modèles sont disponibles dans l’[Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/).\n",
    "\n",
    "La configuration de ce modèle est inspirée du guide suivant : [Guide de configuration OCR](https://docs.openvino.ai/2024/notebooks/handwritten-ocr-with-output.html).\n",
    "\n",
    "### Guide d'Installation\n",
    "\n",
    "Ce tutoriel fonctionne de manière autonome, reposant uniquement sur son propre code.\n",
    "\n",
    "Il est recommandé d’exécuter ce notebook dans un environnement virtuel. Seul un serveur Jupyter est nécessaire pour démarrer. Pour davantage de détails, consultez le [Guide d'Installation](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/README.md#-installation-guide).\n",
    "\n",
    "<img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=5b5a4db0-7875-4bfb-bdbd-01698b5b1a77&file=notebooks/handwritten-ocr/handwritten-ocr.ipynb\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d4fddb-25cf-4e37-a3a0-879fa78cfb42",
   "metadata": {},
   "source": [
    "## Import de modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uVY1F-uowMbu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVY1F-uowMbu",
    "outputId": "c6665548-3f3e-469a-e3be-f052c9052ec7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installer les paquets nécessaires\n",
    "%pip install -q \"openvino>=2023.1.0\" opencv-python tqdm \"matplotlib>=3.4\"\n",
    "\n",
    "from collections import namedtuple, defaultdict\n",
    "from itertools import groupby\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openvino as ov\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Récupérer le module `notebook_utils`\n",
    "r = requests.get(\n",
    "    url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py\",\n",
    ")\n",
    "open(\"notebook_utils.py\", \"w\").write(r.text)\n",
    "from notebook_utils import download_file, device_widget\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "!pip install -U jupyter ipywidgets notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bbf833-d5df-4662-8504-5777b0971e5e",
   "metadata": {},
   "source": [
    "## Téléchargement et Configuration du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RXrGz0b70d3W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "RXrGz0b70d3W",
    "outputId": "802ec0c7-374f-4b99-e33c-167ec8a1d34a"
   },
   "outputs": [],
   "source": [
    "# Définition des répertoires pour les modèles et les données\n",
    "base_models_dir = \"./chinese_handwritten_models\"  # Répertoire pour les modèles téléchargés\n",
    "data_folder = \"./chinese_handwritten_data\"  # Répertoire pour les données d'entrée\n",
    "charlist_folder = f\"{data_folder}/text\"  # Sous-répertoire pour la liste de caractères\n",
    "\n",
    "# Spécification de la précision du modèle (FP16 pour une inférence rapide et légère)\n",
    "precision = \"FP16\"\n",
    "\n",
    "# Structure nommée 'Language' pour regrouper les informations du modèle\n",
    "Language = namedtuple(\"Language\", [\"model_name\", \"charlist_name\", \"demo_image_name\"])\n",
    "\n",
    "# Initialisation des fichiers pour le chinois simplifié\n",
    "chinese_files = Language(\n",
    "    model_name=\"handwritten-simplified-chinese-recognition-0001\",\n",
    "    charlist_name=\"chinese_charlist.txt\",\n",
    "    demo_image_name=\"handwritten_chinese_test.jpg\",\n",
    ")\n",
    "\n",
    "# Téléchargement des fichiers du modèle OpenVINO\n",
    "path_to_model = download_file(\n",
    "    url=f\"https://storage.openvinotoolkit.org/repositories/open_model_zoo/2023.0/models_bin/1/{chinese_files.model_name}/{precision}/{chinese_files.model_name}.xml\",\n",
    "    directory=base_models_dir,\n",
    ")\n",
    "\n",
    "# Téléchargement du fichier .bin contenant les poids du modèle\n",
    "_ = download_file(\n",
    "    url=f\"https://storage.openvinotoolkit.org/repositories/open_model_zoo/2023.0/models_bin/1/{chinese_files.model_name}/{precision}/{chinese_files.model_name}.bin\",\n",
    "    directory=base_models_dir,\n",
    ")\n",
    "\n",
    "# Initialisation d'OpenVINO pour l'inférence\n",
    "core = ov.Core()\n",
    "\n",
    "# Chargement du modèle avec son fichier XML\n",
    "model = core.read_model(model=path_to_model)\n",
    "\n",
    "# Sélection du périphérique pour l'inférence avec un widget interactif\n",
    "device = device_widget()  # Assurez-vous que device_widget est défini\n",
    "\n",
    "# Compilation du modèle pour le dispositif sélectionné\n",
    "compiled_model = core.compile_model(model=model, device_name=device.value)\n",
    "\n",
    "# Extraction des couches d'entrée et de sortie du modèle\n",
    "recognition_output_layer = compiled_model.output(0)  # Couche de sortie\n",
    "recognition_input_layer = compiled_model.input(0)  # Couche d'entrée\n",
    "\n",
    "# Téléchargement de la liste de caractères pour le décodage des prédictions\n",
    "used_charlist_file = download_file(\n",
    "    f\"https://storage.openvinotoolkit.org/repositories/openvino_notebooks/data/data/text/{chinese_files.charlist_name}\",\n",
    "    directory=charlist_folder,\n",
    ")\n",
    "\n",
    "# Préparation de la liste de caractères pour le décodage\n",
    "blank_char = \"~\"\n",
    "with open(used_charlist_file, mode=\"r\", encoding=\"utf-8\") as charlist:\n",
    "    letters = blank_char + \"\".join(line.strip() for line in charlist)  # Ajout d'un caractère vide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66115c6-109a-482e-a72f-11b205e97e2b",
   "metadata": {},
   "source": [
    "## Fonction de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B2_NKznL05NS",
   "metadata": {
    "id": "B2_NKznL05NS"
   },
   "outputs": [],
   "source": [
    "def OCR_OpenVINO(compiled_model, input_directory, charlist, recognition_input_layer, recognition_output_layer, reference_from) -> list:\n",
    "    \"\"\"\n",
    "    Effectue la reconnaissance optique de caractères (OCR) sur des images d'un répertoire donné \n",
    "    à l'aide d'un modèle OpenVINO.\n",
    "\n",
    "    :param compiled_model: Modèle compilé d'OpenVINO pour l'inférence.\n",
    "    :param input_directory: Répertoire contenant les images à traiter.\n",
    "    :param charlist: Liste des caractères utilisée pour le décodage (incluant un symbole vide).\n",
    "    :param recognition_input_layer: Couche d'entrée du modèle de reconnaissance.\n",
    "    :param recognition_output_layer: Couche de sortie du modèle de reconnaissance.\n",
    "    :param reference_from: Indicateur pour définir la source des références (\"file_name\" ou \"dir_name\").\n",
    "    :return: Liste des textes prédits pour chaque image ainsi que les références associées.\n",
    "    \"\"\"\n",
    "    # Liste pour stocker les textes prédits pour chaque image\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    # Parcourir chaque image dans le répertoire spécifié\n",
    "    for path_image in Path(input_directory).glob(\"*\"):\n",
    "        if path_image.suffix in (\".jpg\", \".png\", \".jpeg\"):  # Vérifier l'extension de fichier\n",
    "            # Lire l'image en niveaux de gris\n",
    "            image = cv2.imread(str(path_image), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "            if image is None:\n",
    "                print(f\"Avertissement : Impossible de lire l'image {path_image}. Passage à l'image suivante.\")\n",
    "                continue\n",
    "    \n",
    "            # Obtenir les dimensions de l'image\n",
    "            image_height, image_width = image.shape\n",
    "    \n",
    "            # Récupérer la forme d'entrée du modèle\n",
    "            _, _, H, W = recognition_input_layer.shape\n",
    "    \n",
    "            # Calculer le ratio de redimensionnement pour ajuster la hauteur\n",
    "            scale_ratio = H / image_height\n",
    "    \n",
    "            # Redimensionner l'image en fonction de la hauteur\n",
    "            new_width = int(image_width * scale_ratio)\n",
    "            resized_image = cv2.resize(image, (new_width, H), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "            # Compléter l'image pour correspondre à la largeur d'entrée sans changer l'aspect\n",
    "            if resized_image.shape[1] < W:\n",
    "                resized_image = np.pad(resized_image, ((0, 0), (0, W - resized_image.shape[1])), mode=\"constant\", constant_values=255)\n",
    "    \n",
    "            # Reshape pour correspondre à la forme d'entrée du modèle\n",
    "            input_image = resized_image[None, None, :, :]  # Préparation pour l'entrée réseau\n",
    "    \n",
    "            # Effectuer l'inférence avec le modèle\n",
    "            predictions_output = compiled_model([input_image])[recognition_output_layer]\n",
    "    \n",
    "            # Supprimer la dimension de lot\n",
    "            predictions_output = np.squeeze(predictions_output)\n",
    "    \n",
    "            # Obtenir les indices des classes prédites\n",
    "            predictions_indexes = np.argmax(predictions_output, axis=1)\n",
    "    \n",
    "            # Utiliser `groupby` pour supprimer les lettres consécutives selon le décodage CTC\n",
    "            output_text_indexes = list(groupby(predictions_indexes))\n",
    "            output_text_indexes, _ = np.transpose(output_text_indexes, (1, 0))  # Éliminer les objets grouper\n",
    "            output_text_indexes = output_text_indexes[output_text_indexes != 0]  # Supprimer les symboles vides\n",
    "            \n",
    "            # Mapper les indices aux caractères correspondants\n",
    "            output_text = \"\".join([charlist[letter_index] for letter_index in output_text_indexes])\n",
    "    \n",
    "            # Stocker la prédiction\n",
    "            predictions.append(output_text if output_text else \"None\")\n",
    "\n",
    "            # Récupérer la référence selon le type spécifié\n",
    "            if reference_from == \"file_name\":\n",
    "                references.append(path_image.stem[0])  # Prendre le premier caractère du nom de fichier\n",
    "            elif reference_from == \"dir_name\":\n",
    "                references.append(str(path_image.parent.name))  # Prendre le nom du répertoire parent\n",
    "\n",
    "    return predictions, references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d1996-6d1b-4500-ab53-c9a5c9c52a69",
   "metadata": {},
   "source": [
    "## Fonction d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0a665-3dbc-4c60-9cca-71eaa743a38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluation(predictions, references):\n",
    "    \"\"\"\n",
    "    Évalue la précision, le rappel et le score F1 pour une tâche OCR\n",
    "    avec des images correspondant à un seul caractère. \n",
    "    Retourne les moyennes macro et weighted.\n",
    "\n",
    "    :param predictions: Liste des caractères prédits par le modèle.\n",
    "    :param references: Liste des caractères de référence (attendus).\n",
    "    :return: Dictionnaire des scores de précision, rappel et F1 pour les moyennes macro et weighted,\n",
    "             ainsi qu'un rapport de classification détaillé pour chaque caractère de référence.\n",
    "    \"\"\"\n",
    "    if not predictions:  # Vérifie si la liste des prédictions est vide\n",
    "        print(\"Erreur : Les prédictions sont vides.\")\n",
    "        return {\n",
    "            \"Précision (macro)\": 0, \"Rappel (macro)\": 0, \"Score F1 (macro)\": 0,\n",
    "            \"Précision (weighted)\": 0, \"Rappel (weighted)\": 0, \"Score F1 (weighted)\": 0\n",
    "        }, {}\n",
    "\n",
    "    # Calcul des scores avec gestion des divisions par zéro\n",
    "    results = {\n",
    "        \"Précision (macro)\": precision_score(references, predictions, average=\"macro\", zero_division=0),\n",
    "        \"Rappel (macro)\": recall_score(references, predictions, average=\"macro\", zero_division=0),\n",
    "        \"Score F1 (macro)\": f1_score(references, predictions, average=\"macro\", zero_division=0),\n",
    "        \"Précision (weighted)\": precision_score(references, predictions, average=\"weighted\", zero_division=0),\n",
    "        \"Rappel (weighted)\": recall_score(references, predictions, average=\"weighted\", zero_division=0),\n",
    "        \"Score F1 (weighted)\": f1_score(references, predictions, average=\"weighted\", zero_division=0)\n",
    "    }\n",
    "\n",
    "    # Crée un rapport détaillé en utilisant uniquement les labels présents dans les références\n",
    "    unique_labels = sorted(set(references))\n",
    "    classification_rep = classification_report(references, predictions, labels=unique_labels, output_dict=True, zero_division=0)\n",
    "\n",
    "    return results, classification_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbaf1ff-7c70-43c5-b9a7-9d4b2db57bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caractères Guilhem\n",
    "test_directory = \"Char/\"\n",
    "all_predictions_chars_Guilhem, all_references_chars_Guilhem = OCR_OpenVINO(compiled_model,\n",
    "                                                                           test_directory,\n",
    "                                                                           letters,\n",
    "                                                                           recognition_input_layer,\n",
    "                                                                           recognition_output_layer,\n",
    "                                                                           reference_from=\"file_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bacc817-f1a1-42c6-b521-e7714ec39b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caractères Corpus Test\n",
    "test_directory = \"data/NewData120/Test/\"\n",
    "all_predictions_120Test, all_references_120Test = [], []\n",
    "for directory in Path(test_directory).iterdir():\n",
    "    predictions_per_char, references_per_chars = OCR_OpenVINO(compiled_model,\n",
    "                                                              directory,\n",
    "                                                              letters,\n",
    "                                                              recognition_input_layer,\n",
    "                                                              recognition_output_layer,\n",
    "                                                              reference_from=\"dir_name\")\n",
    "    all_predictions_120Test += predictions_per_char\n",
    "    all_references_120Test += references_per_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7fa1a7-9ce8-4941-ade7-513c252f5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Chemin de sauvegarde pour les fichiers pickle\n",
    "predictions_path = \"all_predictions_120Test.pkl\"\n",
    "references_path = \"all_references_120Test.pkl\"\n",
    "\n",
    "# Sauvegarder les prédictions\n",
    "with open(predictions_path, \"wb\") as f:\n",
    "    pickle.dump(all_predictions_120Test, f)\n",
    "\n",
    "# Sauvegarder les références\n",
    "with open(references_path, \"wb\") as f:\n",
    "    pickle.dump(all_references_120Test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884dc3c-7b5d-46a4-af78-aa837c5be530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation\n",
    "results_120Test, report_120Test = evaluation(all_predictions_120Test, all_references_120Test)\n",
    "results_chars_Guilhem, report_chars_Guilhem = evaluation(all_predictions_chars_Guilhem, all_references_chars_Guilhem)\n",
    "\n",
    "print(\"Scores globaux pour le corpus de test de Guilhem :\")\n",
    "for metric, score in results_chars_Guilhem.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Scores globaux pour le corpus de test  :\")\n",
    "for metric, score in results_120Test.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nRapport de classification détaillé pour le corpus de test :\")\n",
    "for label, metrics in report_120Test.items():\n",
    "    if label not in ['micro avg', 'macro avg', 'weighted avg']:\n",
    "        print(f\"Caractère : {label}\")\n",
    "    else:\n",
    "        print(label)\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b53f1-24c2-45d6-b682-1432156e8ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "ae617ccb002f72b3ab6d0069d721eac67ac2a969e83c083c4321cfcab0437cd1"
  },
  "kernelspec": {
   "display_name": "Python (tal)",
   "language": "python",
   "name": "tal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "openvino_notebooks": {
   "imageUrl": "https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/handwritten-ocr/handwritten-ocr.png?raw=true",
   "tags": {
    "categories": [
     "Model Demos"
    ],
    "libraries": [],
    "other": [],
    "tasks": [
     "Image-to-Text"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
